\chapter{One Dimensional Stochastic Case}\label{chap:one-d-stochastic}

Here we return to the one dimensional version of this equation, but this time
we introduce some form of uncertainty in the coefficients of the equation:

\begin{equation}\label{eq:oned-stochastic}
  \begin{aligned}
      -\frac{d}{dx}\left[\kappa(x;\omega)\frac{d}{dx}u(x;\omega)\right] &= f(x)\,
                              &x \in  D = [-1,1]\, \omega \in \Omega \\
    u(x;\omega) &= 0 &x \in \partial D = \{-1,1\}\, \omega \in \Omega
  \end{aligned}
\end{equation}

where $\Omega$ is a probability space. In order to handle this case, we follow
a similar method to that we used in Chapter \ref{chap:oned-deterministic}
however with the introduction of the random parameter $\omega$ there is an
additional layer of complexity to deal with, as well as discretising the
physical domain we also need to be able to discretise the probability space
using a finite dimensional approximation.  This is where the generalised
polynomial chaos comes in.

Using the methodology outlined in \cite{general-poly-chaos} we can use various
polynomials in the \textit{Askey Scheme} to construct a finite dimensional
approximate representations of various random processes which when used in
conjunction with the Finite Element Method we can model the expected behaviour
of the solution process $u(x;\omega)$

\section{Weak Formulation}

\todo[inline]{Make exact all the functional spaces etc.}

As with the deterministic cases, we first need to obtain the weak formulation
of the problem, where we multiply through by $w \in W$ and integrate over the
domain.

\begin{equation}
    -\int_{\Omega}\int_{-1}^1\left(\frac{d}{dx}\left[\kappa(x;\omega)\frac{d}{dx}u(x;\omega)\right]
    w(x;\omega)\right)\, dx\, d\Omega = \int_{\Omega}\int_{-1}^1 f(x)w(x;\omega)\, dx\, d\Omega
\end{equation}

Proceeding with integration by parts

\begin{equation}
    -\int_{\Omega}\left(
      \underbrace{\left[\kappa(x;\omega)\frac{d}{dx}u(x;\omega)
                        w(x;\omega)\right]_{-1}^1}_{= 0}
       -\int_{-1}^1\kappa(x;\omega)\frac{d}{dx}u(x;\omega)\frac{d}{dx}w(x;\omega)\, dx
    \right)\, d\Omega = \int_{\Omega}\int_{-1}^1 f(x)w(x;\omega)\, dx\, d\Omega
\end{equation}

where the underbraced term is zero as the elements of $W$ are zero at the
endpoints of the domain. Hence the weak form of this equation is given by:

\begin{equation}\label{eq:wk-one-d-stochastic}
    \int_{\Omega}\int_{-1}^1\kappa(x;\omega)
           \frac{d}{dx}u(x;\omega)\frac{d}{dx}w(x;\omega)\, dx\, d\Omega =
           \int_{\Omega}\int_{-1}^1 f(x)w(x;\omega)\, dx\, d\Omega
\end{equation}

where finding a solution in this sense would be to find a $u \in V$ such that
the above is satisfied $\forall w \in W$

\section{Discrete Formulation}

Constructing a finite dimensional approximation to
\myref{eq:wk-two-d-stochastic} requires us to discretise both physical and
probability spaces. For the physical space we can proceed in a similar fashion
to Chapter \ref{chap:oned-deterministic} taking into account that the domain
now extends to include the interval $[-1, 0]$

Given a parameter $N \in \mathbb{N}$ we place $N+1$ equally spaced nodes
$x_i, i \in \{0,\ldots,N\}$ in the interval $[-1,1]$ such that $x_0= -1$,
$x_N = 1$. This subdivides the interval into $N$ subintervals
$I_i = [x_i, x_{i+1}]$, for each $i \in \{0,\ldots,N-1\}$. These subintervals
will have length $h = 1/N$ and we can define our discretisation as follows:

\[
    D^h = \bigcup_{i=0}^{N - 1}I_i
\]

Upon which we can define finite dimensional subspaces of $V$ and $W$:

\begin{align*}
    V^h &= \{v \in V : v \text{ is linear on } I_i,\ i \in \{0,\ldots,N-1\},
                    \  v \text{ is continuous on } [-1,1]\} \\
    W^h &= \{w \in W : w \text{ is linear on } I_i,\ i \in \{0,\ldots,N-1\},
                    \  w \text{ is continuous on } [-1,1]\}
\end{align*}

Then we can choose the `hat functions' as our basis again which are defined
just as they were in \ref{eq:one-d-hat-basis} hence we can approximate $f(x)$
as follows:

\begin{equation}\label{eq:oned-stochastic-f-approx}
    f(x) \approx \sum_{j=0}^Nf_j\phi_i(x)
\end{equation}

where $f_j = f(x_j)$. This also allows us to write our approximate solution
process $u^h$ as follows:

\begin{equation}\label{eq:oned-stochastic-uh}
    u^h(x;\omega) = \sum_{j=0}^Nu_j(\omega)\phi_j(x)
\end{equation}

We now have a discrete representation for $u^h$ in the physical space but now
we need to turn our attention to approximating the diffusion coefficient
$\kappa(x;\omega)$ and the stochastic parts of the solution process
$u_j(\omega)$

\subsection{Polynomial Chaos}

Much like the physical case, constructing a finite dimensional approximation to
a probability space requires choosing a set of orthogonal functions to form a
basis which spans the space. As shown in \cite{gpc} members from the
\textit{Askey Scheme} of orthogonal polynomials can be used to construct finite
dimensional approximations to second order random processes.

Depending on the probability measure of a space a different set of polynomials
are used. For example if the probability measure is for a
\textit{Gaussian process} then the \textit{Hermite polynomials} are used or in
the case of a \textit{Uniform process} the \textit{Legendre polynomials} are
used. A full table outlining the correspondence of probability measures to
polynomials can be found in \cite{general-poly-chaos}

Once the set of polynomials have been determined you can approximate a random
process as follows:

\begin{equation}
    \omega(\theta) = \sum_{s=0}^P\omega_s\chi_s(\theta)
\end{equation}

where $P = (d + p)!/d!p!$ and $d$ denotes the dimensionality of the
approximation and $p$ is the highest degree of polynomial used. For example in
the case of Legendre polynomials and $d=2$, $p=2$ that gives a total of 6
terms in the expansion. We can then define the following index scheme:

\begin{equation}
  \begin{array}{c c c }
    \alpha_1 = (0,0) & \alpha_2 = (1,0) & \alpha_3 = (0,1) \\
    \alpha_4 = (2,0) & \alpha_5 = (1,1) & \alpha_6 = (0,2)
  \end{array}
\end{equation}

Then the set of basis polynomials in this case would be given by:

\begin{equation}
  \begin{array}{l l l}
    \chi_{\alpha_1} = 1 & \chi_{\alpha_2} = \xi_1 & \chi_{\alpha_3} = \xi_2 \\
    \chi_{\alpha_4} = \frac{1}{2}(3\xi_1^2 - 1) &
    \chi_{\alpha_5} = \xi_1\xi_2 &
    \chi_{\alpha_6} = \frac{1}{2}(3\xi_2^2 - 1)
  \end{array}
\end{equation}

Therefore we may now rewrite our approximation to the solution process
\myref{eq:oned-stochastic-uh} as follows:

\begin{equation}\label{eq:oned-stochastic-uhp}
    u^{h,P}(x;\omega) = \sum_{j=0}^N\sum_{s=1}^Pu_{j,s}\chi_s(\omega)\phi_j(x)
\end{equation}

\subsection{The Karhunen-Loeve Expansion}

The Karhunen-Loeve (KL) expansion allows us to write any second order
stochastic process $X(\v{x},\omega)$ in the following way:

\begin{equation}
    X(\v{x}, \omega) = \bar{X}(\v{x})
    + \sum_{n = 0}^\infty\sqrt{\lambda_n}\beta_n(\v{x})\xi_n(\omega)
\end{equation}

where:

\begin{itemize}
    \item $\bar{X}(\v{x})$ denotes the expected value of the process
    \item $\{\xi_n(\omega)\}_{n=0}^\infty$ forms a set of uncorrelated random
          variables
    \item $\lambda_n$, $\beta_n(\v{x})$ denote the eigenvalues/eigenfunctions
          of the following eigenvalue problem:
          \[
                \int_DC(\v{x}_1, \v{x}_2)\beta(\v{x})\, d\v{x}_1
                = \lambda\beta(\v{x}_2)
          \]
          where $C(\v{x}_1,\v{x}_2)$ denotes the correlation function of the
          random process.
\end{itemize}

The derivation of this representation is discussed in \cite{stochastic-fem} as
well as a number of its properties. One such property which is useful for our
purposes is that this representation is optimal in the sense that when we
truncate the series to a finite number of terms the mean squared error is
minimised.

Of course since this representation requires that we know the correlation
function of the random process so this will only be useful for expanding the
term $\kappa(x;\omega)$ in \myref{eq:oned-stochastic}.

For the purposes of this project we will assume that $\kappa(x;\omega)$ is
uniformly distributed between the values $a$ and $b$ with mean $\mu$,
variance $\sigma^2$ and correlation function given by:

\begin{equation}
    C(x, y) = \sigma^2\exp\left(-\frac{|x - y|}{k}\right)
\end{equation}

where $k$ is the correlation length that for simplicity we set to $1$.
Therefore to determine $\beta_n, \lambda_n$ we have to solve the following
integral equation:

\begin{equation}
    \sigma^2\int_{-1}^1\exp(-|x - y|)\beta_n(y) dy = \lambda_n\beta_n(x)
\end{equation}

A detailed discussion on finding the eigenvalues/eigenfunctions above can be
found in \cite{stochastic-fem} but solving this numerically using
\todo{Have a look at pychebfun or chebpy} PYTHON LIBRARY
will be sufficient for our purposes.

Therefore we can approximate $\kappa$ as follows:

\begin{align}\label{eq:oned-stochastic-kl-kappa}
    \kappa(x;\omega) &\approx \mu + \sigma\sum_{l=1}^d\sqrt{\lambda_l}\beta_l(x)\xi_l(\omega)
\end{align}

\subsection{Derivation of Global System of Equations}

Since the weak formulation \myref{eq:wk-one-d-stochastic} has to be satisifed
$\forall w \in W$ it must in particular hold for the basis functions. So by
using the expansions \myref{eq:oned-stochastic-uhp},
\myref{eq:oned-stochastic-f-approx} and \myref{eq:oned-stochastic-kl-kappa} and
choosing $w = \phi_i(x)\chi_t(x)$ for each $i = \{0,\ldots,N\}$ and each $t =
\{0,\ldots,P\}$ and substituting into \myref{eq:wk-one-d-stochastic} we
obtain:

\begin{align*}
    \int_{\Omega}\int_{-1}^1
      \left(\mu + \sum_{l=1}^d\sqrt{\lambda_l}\beta_l(x)\xi_l(\omega)\right)
      \frac{d}{dx}\left(\sum_{j=0}^N\sum_{s=1}^Pu_{s,j}\phi_j(x)\chi(\omega)\right)
      \phi_i'(x)\chi_t(\omega)\, dx\, d\Omega \\ =
    \int_{\Omega}\int_{-1}^1
      \left(\sum_{j=0}^Nf_j\phi_j(x)\right)
      \phi_i(x)\chi_t(\omega)\, dx\, d\Omega
\end{align*}

Then by the linearity of the integral and differential operator we may write
this as:

\begin{align}\label{eq:oned-stochastic-discrete}
  \begin{split}
      \sum_{j=0}^N\sum_{s=0}^Pu_{s,j}\left[
        \mu\int_\Omega\int_{-1}^1
          \phi_j'(x)\phi_i'(x)\chi_s(\omega)\chi_t(\omega)\, dx\, d\Omega +
          \sum_{l=1}^d\sqrt{\lambda_l}\left(\int_\Omega\int_{-1}^1
          \beta_l(x)\phi_j'(x)\phi_i(x)
      \xi_l(\omega)\chi_s(\omega)\chi_t(\omega)\, dx\, d\Omega\right)
      \right]\\ =
      \sum_{j=0}^N\sum_{s=0}^Pf_j\left(\int_\Omega\int_{-1}^1\phi_j(x)\phi_i(x)
      \chi_s(\omega)\chi_t(\omega)\, dx\, d\Omega\right)
  \end{split}
\end{align}

for each $j \in \{1,\ldots,N\}$ and each $t \in \{1,\ldots,P\}$. Which defines
a $NP \times NP$ system of linear equations $A\v{u} = M\v{f}$ in which the
global stiffness matrix $A$ takes the following form:

\begin{equation}
    A = \left[\begin{array}{c c c}
            A_{1,1} & \cdots & A_{1,P} \\
            \vdots & & \vdots \\
            A_{P,1} & \cdots & A_{P,P}
        \end{array}\right]
\end{equation}

where each $A_{s,t}$ are $N \times N$ matrices and the $i$-th, $j-$th component
of the matrix $A_{s,t}$ is given by the terms contained in square brackets in
\myref{eq:oned-stochastic-discrete}. Similarly the global mass matrix $M$ takes
the form:

\begin{equation}
    M = \left[\begin{array}{c c c}
            M_{1,1} & \cdots & M_{1,P} \\
            \vdots & & \vdots \\
            M_{P,1} & \cdots & M_{P,P}
        \end{array}\right]
\end{equation}

where each $M_{s,t}$ are $N \times N$ matrices with the $i$-th, $j$-th
component of the matrix $M_{s,t}$ is given by the term in parenthesis on the
second line in \myref{eq:oned-stochastic-discrete}

\section{Constructing the Global System}

In order to construct the global system of equations we need to determine the
form of each of the smaller $N \times N$ matrices $A_{s,t}$

\subsection{The Matrices on the Diagonal}

By setting $s=t$ in \myref{eq:oned-stochastic-discrete} we obtain the following
expression for the entries of the matrices sitting on the diagonal of the
global stiffness matrix:

\begin{equation}
    A_{s,s} = \sum_{j=0}^N\left(\mu\int_\Omega\int_{-1}^1
       \phi_j'(x)\phi_i'(x)\chi_s(\omega)\chi_s(\omega)\, dx\, d\Omega
       + \sum_{l=1}^d\sqrt{\lambda_n}\int_\Omega\int_{-1}^1
       \beta_l(x)\phi_j'(x)\phi_i'(x)\xi_l(\omega)\chi_s(\omega)\chi_s(\omega)
       \, dx\, d\Omega  \right)
\end{equation}

for each $i \in \{0,\ldots,N\}$.

\begin{equation}
    A_{s,s} = \mu\langle\chi_s^2\rangle\sum_{j=0}^N\left(\int_{-1}^1
                \phi_j'(x)\phi_i'(x)\, dx\right)
\end{equation}

for each $i \in \{0,\ldots,N\}$.

\subsection{The Off-Diagonal Matrices}

Now if we consider the off diagonal matrices:

\begin{equation}\label{eq:oned-stochastic-off-diagonal-stiffness}
    A_{s,t} = \sum_{j=0}^N\left(\mu\int_\Omega\int_{-1}^1
       \phi_j'(x)\phi_i'(x)\chi_s(\omega)\chi_t(\omega)\, dx\, d\Omega
       + \sum_{l=1}^d\sqrt{\lambda_n}\int_\Omega\int_{-1}^1
    \beta_l(x)\phi_j'(x)\phi_i'(x)\xi_l(\omega)\chi_s(\omega)\chi_t(\omega)
       \, dx\, d\Omega  \right)
\end{equation}

for each $i \in \{0,\ldots,N\}$. The polynomial bases $\chi_s$ are chosen so
that with respect to the probability measure for the space, they satisfy the
following orthogonality relation:

\begin{align*}
    \langle\chi_s\chi_t\rangle
      &= \int_\Omega\chi_s(\omega)\chi_t(\omega)\, d\Omega \\
      &= \langle\chi_s\rangle^2\delta_{st}
\end{align*}

therefore as $s \neq t$ for matrices off the principal diagonal, the first term
in \myref{eq:oned-stochastic-off-diagonal-stiffness} vanishes.


\begin{equation}
    A_{s,t} = \sum_{j=0}^N
        \sum_{l=1}^d\sqrt{\lambda_n}\int_\Omega\int_{-1}^1
       \beta_l(x)\phi_j'(x)\phi_i'(x)\xi_l(\omega)\chi_s(\omega)\chi_t(\omega)
       \, dx\, d\Omega
\end{equation}

